---
title: "PCA - Example on the Iris data"
author: "YOUR NAME"
date: "`r Sys.Date()`"
output: html_document
---

# PCA on the Iris data

```{r, message=FALSE}
library(tidyverse)
```

## Load and inspect the data
0. First we load the iris data set.
```{r}
data(iris)
```

1. Recall how the data looked like: Use `head()` or `View()` to inspect the data. How many features and samples are in the data?
```{r}
head(iris)
nrow(iris)
```
The data contains 4 numerical measurements (features) for each flower (Sepal.Length Sepal.Width Petal.Length Petal.Width) and a label on which Species the flower is.


2. We will again separate the label on the species and the numerical measurements (contained in the first 4 columns). Create two new objects: one matrix `iris_x` containing the numerical measurements as a matrix and one character vector  `irsi_species` containing the species label.
```{r}
iris_x <- as.matrix(iris[,1:4])
irsi_species <- iris$Species
```

3. Remember how the data looked like by using the `ggpairs` function form the `GGally` package to produce pairwise scatterplots.
```{r}
# to be filled
```


## PCA
To calculate the principal components in this data we can use the `prcomp` function. 
```{r}
pca.out <- prcomp(iris_x)
```

Take a look at the output. What class is it? What information does it hold? What dimensions have the `rotation` and `x` matrices in the output?
```{r}
# to be filled
```

Call the summary function on the output of the PCA. What does this tell you?
```{r}
# to be filled
```

Make a screeplot (or elbow plot) showing the percentage of variance explained in the data for each principal component. (Hint: You can extract this from the summary object above or use `pca.out$sdev^2/sum(pca.out$sdev^2)` to recalculate them.
```{r}
# to be filled
```


We can use the `ggfortify` package and the `autoplot` function to generate PCA plot using the ggplot syntax.
```{r}
library(ggfortify)
autoplot(pca.out, colour = "Species", data = iris, scale = FALSE) +
  theme_bw() + coord_fixed()
```

We can also add the information on the feature loadings in form of a biplot by setting `loadings = TRUE`.
```{r}
autoplot(pca.out, data = iris, colour = 'Species',  scale = FALSE,
         loadings = TRUE, loadings.colour = 'blue',
         loadings.label = TRUE, loadings.label.size = 3) +
  theme_bw() + coord_fixed()
```
Questions:

- How do you interpret the arrows? How does this relate to the rotation matrix in `pca.out`?
- What is `coord_fixed` doing and why would it be useful?

By setting the arguments `x` and `y` in the `autoplot` function we can also visualize higher-order principal components. Use this to generate a plot of components 3 versus 4. Again you can add the loading information in terms of a biplot.
```{r}
# to be filled
```


Exercise: Generate the PCA plot using the standard ggplot commands starting from the `pca.out` object (without using `autoplot` function).
```{r}
# to be filled
```

Exercise: Use k-means clustering to (again) cluster the data into 3 clusters and add the cluster ids obtained from kmeans clustering and color by clusters in the PCA plot.
```{r}
# to be filled
```


Advanced exercise: Calculate and plot a tSNE embedding of the data. How does it relate to PCA? How do the parameters of the algorithm affect the embedding? Test different perplexity parameters (e.g. 2,5,10, 40). Hint: Install and load the `Rtsne` package for this. Note: Use the option `check_duplicates = FALSE` to avoid errors due to duplicated data points.
```{r}
# to be filled
```

Advanced exercise: Calculate and plot a UMAP embedding of the data. How does it relate to PCA? How do the parameters of the algorithm affect the embedding? Test different `n_neighbors` parameters (e.g. 5,10, 20, 50). Hint: Install and load the `umap` package for this. Note: Use the option `check_duplicates = FALSE` to avoid errors due to duplicated data points.
```{r}
# to be filled
```

```{r}
sessionInfo()
```

